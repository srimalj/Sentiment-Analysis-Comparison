{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute NLTK and Transformers sentiment scores on labelled dataset\n",
    "\n",
    "### References\n",
    "- Transformers: https://huggingface.co/transformers/quicktour.html\n",
    "\n",
    "### Datasets\n",
    "- UCI: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srimal/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Text</th>\n",
       "      <th>GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Good case, Excellent value.\\t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Great for the jawbone.\\t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source                                               Text GT\n",
       "0  amazon  So there is no way for me to plug it in here i...  0\n",
       "1  amazon                      Good case, Excellent value.\\t  1\n",
       "2  amazon                           Great for the jawbone.\\t  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read datasets\n",
    "\n",
    "def readFile(filepath, source):\n",
    "    df = pd.read_csv('../data/raw/uci-sentiment/amazon_cells_labelled.txt', sep=\"NO_SEPARATORS\", names=['Data'])\n",
    "    df['GT'] = df.Data.apply(lambda x: x[-1:])\n",
    "    df['Text'] = df.Data.apply(lambda x: x[0: len(x)-1])\n",
    "    df['Source'] = source\n",
    "    return df[['Source', 'Text', 'GT']]\n",
    "\n",
    "amazon = readFile('../data/raw/uci-sentiment/amazon_cells_labelled.txt','amazon')\n",
    "imdb = readFile('../data/raw/uci-sentiment/imdb_labelled.txt', 'imdb')\n",
    "yelp = readFile('../data/raw/uci-sentiment/yelp_labelled.txt', 'yelp')\n",
    "df = pd.concat([amazon, imdb, yelp])\n",
    "\n",
    "display(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 729 ms, sys: 46.5 ms, total: 776 ms\n",
      "Wall time: 781 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/srimal/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.671, 'neu': 0.329, 'pos': 0.0, 'compound': -0.6214}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Text</th>\n",
       "      <th>GT</th>\n",
       "      <th>NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.3535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Good case, Excellent value.\\t</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Great for the jawbone.\\t</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source                                               Text GT    NLTK\n",
       "0  amazon  So there is no way for me to plug it in here i...  0 -0.3535\n",
       "1  amazon                      Good case, Excellent value.\\t  1  0.8402\n",
       "2  amazon                           Great for the jawbone.\\t  1  0.6249"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "display(sia.polarity_scores(\"Wow, NLTK is really powerful!\"))\n",
    "display(sia.polarity_scores(\"absolutely really bad\"))\n",
    "\n",
    "df['NLTK'] = df['Text'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9996577501296997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9998730421066284"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9854032397270203"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 308 ms, total: 1.46 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def tfScore(text, classifier):\n",
    "    try:\n",
    "        r = classifier(text)\n",
    "        if r[0]['label'] == 'NEGATIVE':\n",
    "            return -1.0 * r[0]['score']\n",
    "        else:\n",
    "            return r[0]['score']        \n",
    "    except Exception as e:\n",
    "        display(f'ERROR:')\n",
    "        display(f'- Text:  \"{text}\"')\n",
    "        display(f'- Exception:  \"{e}\"')\n",
    "        return np.nan\n",
    "        \n",
    "\n",
    "def getTFScore(text, classifier):\n",
    "    score = tfScore(text, classifier)\n",
    "    return score\n",
    "\n",
    "    \n",
    "tfSentiment = pipeline('sentiment-analysis')\n",
    "\n",
    "display(getTFScore('I feel horrible', tfSentiment))\n",
    "display(getTFScore('I feel awesome', tfSentiment))\n",
    "display(getTFScore('1', tfSentiment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 22s, sys: 1.71 s, total: 3min 24s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['Transformers'] = df['Text'].apply(lambda x: getTFScore(str(x), tfSentiment))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TextLength'] = df.Text.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../output/1-nltk-transformers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
